{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43edb882",
   "metadata": {},
   "source": [
    "# 1 - dataset_loaders.yaml\n",
    "\n",
    "* This configuration file stores the settings of all datasets that will be utilized during the execution of an experiment, as can be seen in the example below for the **MovieLens 1M** dataset.\n",
    "\n",
    "<!-- Which one is better? -->\n",
    "<!-- * This configuration file stores the settings of all datasets required to run your experiment. Below, there is an example setting for the MovieLens 1M dataset. -->\n",
    "\n",
    "\n",
    "\n",
    "* Template to define a dataset:\n",
    "```yaml\n",
    "# Dataset name\n",
    "    # Variables\n",
    "```\n",
    "\n",
    "* Example:\n",
    "```yaml\n",
    "'MovieLens 1M':\n",
    "    dataset_path: ./data/datasets/MovieLens 1M/\n",
    "    train_size: 0.8\n",
    "    test_consumes: 1\n",
    "    crono: False\n",
    "    random_seed: 0\n",
    " ```\n",
    " \n",
    " * The standard data template for ratings consists of 4 comma-separated columns \n",
    " \n",
    "     user_id,item_id,rating,timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eccd718",
   "metadata": {},
   "source": [
    "# 2 - agents.yaml\n",
    "\n",
    "* As its name suggests, this configuration file stores the settings of all agents utilized in the experiments.\n",
    "\n",
    "\n",
    "* Template to define an agent:\n",
    "```yaml\n",
    "# Recommender agent name\n",
    "    # Agent type (irec/irec/agents.py)\n",
    "      # action_selection_policy:\n",
    "        # Action selection policy (irec/irec/action_selection_policies.py)\n",
    "          # Variables, if any\n",
    "      # value_function:\n",
    "        # Agent's value function (irec/irec/value_functions.py)\n",
    "          # Variables of the value function chosen\n",
    "```\n",
    "\n",
    "* Example\n",
    "```yaml\n",
    "LinearEGreedy: # Recommender agent name\n",
    "  SimpleAgent: # Agent type\n",
    "    action_selection_policy: \n",
    "      ASPEGreedy: # Action selection policy\n",
    "        # variaveis\n",
    "        epsilon: 0.1 \n",
    "    value_function:\n",
    "      LinearEGreedy: # Agent's value function\n",
    "        # variáveis\n",
    "        item_var: 0.01\n",
    "        iterations: 20\n",
    "        num_lat: 10\n",
    "        stop_criteria: 0.0009\n",
    "        user_var: 0.01\n",
    "        var: 0.05\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127bd779",
   "metadata": {},
   "source": [
    "# 3 - agents_search.yaml\n",
    "\n",
    "* As each agent may have a lot of variables, it is common to perform a search to find the best parameters and their combinations to achieve the best results/outcomes possible. So we created a specific file named **agents_search.yaml** to store all the combinations of parameters that a particular agent will execute.\n",
    "\n",
    "* The agent template in this file is the same used in **agents.yaml**, however, as we will execute different combinations of the same agent, our configuration file will have multiple agents with different parameters, as shown in the following example\n",
    "\n",
    "* In the example below, we have used the classic **EGreedy** agent with three different parameter combinations: epsilon 0.2, 0.3, and 0.5. Additionally, from the module `irec/app/generate_search_parameters.py` we can define which parameters will vary and their searching range.\n",
    "\n",
    "\n",
    "```yaml\n",
    "EGreedy:\n",
    "- SimpleAgent:\n",
    "    action_selection_policy:\n",
    "      ASPEGreedy:\n",
    "        epsilon: 0.4\n",
    "    value_function:\n",
    "      EGreedy: {}\n",
    "- SimpleAgent:\n",
    "    action_selection_policy:\n",
    "      ASPEGreedy:\n",
    "        epsilon: 0.3\n",
    "    value_function:\n",
    "      EGreedy: {}\n",
    "- SimpleAgent:\n",
    "    action_selection_policy:\n",
    "      ASPEGreedy:\n",
    "        epsilon: 0.2\n",
    "    value_function:\n",
    "      EGreedy: {}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973b5fb3",
   "metadata": {},
   "source": [
    "# 4 - dataset_agents.yaml\n",
    "\n",
    "* This configuration file stores the agents and their parameters for each dataset. Usually, the agent's parameters vary according to the dataset, therefore it is convenient to store the best values found for each one. The results of a grid search on an agent will tell us which were the best parameters found for them, these data can then be stored in this file in case you want to reproduce the experiment later on.\n",
    "\n",
    "* Template of `dataset_agents.yaml`:\n",
    "```yaml\n",
    "# Dataset name\n",
    "    # Agent 1\n",
    "    # Agent 2\n",
    "    ...\n",
    "    # Agent n\n",
    "```\n",
    "* We can see in the example below the best parameters found for agents **LinUCB** and **LinearEGreedy** in the **MovieLens 1M** dataset.\n",
    "\n",
    "```yaml\n",
    "'MovieLens 1M':\n",
    "  LinUCB:\n",
    "    SimpleAgent:\n",
    "      action_selection_policy:\n",
    "        ASPGreedy: {}\n",
    "      value_function:\n",
    "        LinUCB:\n",
    "          alpha: 1.0\n",
    "          num_lat: 10\n",
    "  LinearEGreedy:\n",
    "    SimpleAgent:\n",
    "      action_selection_policy:\n",
    "        ASPEGreedy:\n",
    "          epsilon: 0.1\n",
    "      value_function:\n",
    "        LinearEGreedy:\n",
    "          item_var: 0.01\n",
    "          iterations: 20\n",
    "          num_lat: 10\n",
    "          stop_criteria: 0.0009\n",
    "          user_var: 0.01\n",
    "          var: 0.05\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4926ae6",
   "metadata": {},
   "source": [
    "# 5 - evaluation_policies.yaml\n",
    "\n",
    "* The evaluation policies are defined in this configuration file. To conduct an experiment, we need to define how the recommendation process will be executed and the user-item interactions. We specify these settings in this file according to the experiment's objectives.\n",
    "\n",
    "\n",
    "* Template of `evaluation_policies.yaml`:\n",
    "```yaml\n",
    "# Evaluation policy name (irec/irec/evaluation_policies.py)\n",
    "    # Variables\n",
    "```\n",
    "* In the example below we can observe one of the evaluation policies implemented in the framework: **Interaction**, with its respective parameters.\n",
    "\n",
    "```yaml\n",
    "FixedInteraction: # Evaluation Policy\n",
    "  # Variables\n",
    "  num_interactions: 100 # Number of interactions for each user\n",
    "  interaction_size: 1 # Number of itens that will be recommended for each interaction\n",
    "  save_info: False # Salvar ou não informações obtidas durante a avaliação\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46ec8c9",
   "metadata": {},
   "source": [
    "# 6 - metric_evaluators.yaml\n",
    "\n",
    "* In this file, it is defined evaluation metrics for an experiment. It specifies how to assess the interactions performed during the evaluation process..\n",
    "\n",
    "* Template of `metric_evaluators.yaml`:\n",
    "```yaml\n",
    "# Evaluation metrics name (irec/irec/metric_evaluators.py)\n",
    "    # Variables\n",
    "```\n",
    "\n",
    "* In the example below we can see the use of an evaluation metric named **UserCumulativeInteractionMetricEvaluator** with its recpective parameters.\n",
    "\n",
    "```yaml\n",
    "UserCumulativeInteractionMetricEvaluator:\n",
    "  # variáveis\n",
    "  interaction_size: 1 # Número de itens recomendados a cada interação\n",
    "  interactions_to_evaluate: # Interações que serão avaliadas\n",
    "    - 5\n",
    "    - 10\n",
    "    - 20\n",
    "    - 50\n",
    "    - 100\n",
    "  num_interactions: 100 # Número de interações\n",
    "  relevance_evaluator_threshold: 3.999 # Rating\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0af15e7",
   "metadata": {},
   "source": [
    "# 7 - defaults.yaml\n",
    "\n",
    "* This configuration file defines the general settings of an experiment. We can specify not only the agents, the base, the policy, and the evaluation metric, but also some additional information.\n",
    "\n",
    "* Example\n",
    "```yaml\n",
    "agent: UCB\n",
    "agent_experiment: agent\n",
    "data_dir: data/\n",
    "dataset_experiment: dataset\n",
    "dataset_loader: 'MovieLens 1M'\n",
    "evaluation_experiment: evaluation\n",
    "evaluation_policy: FixedInteraction\n",
    "metric: Hits\n",
    "metric_evaluator: UserCumulativeInteractionMetricEvaluator\n",
    "pdf_dir: pdf/\n",
    "tex_dir: tex/\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
