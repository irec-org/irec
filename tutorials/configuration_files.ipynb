{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43edb882",
   "metadata": {},
   "source": [
    "# 1 - dataset_loaders.yaml\n",
    "\n",
    "* Este arquivo de configuração armazena todas as configurações das bases que serão utilizadas durante a execução de um experimento, como pode ser visto no exemplo de configuração abaixo para a base MovieLens 1M.\n",
    "\n",
    "\n",
    "* Template utilizado para definição de um dataset:\n",
    "```yaml\n",
    "# Nome do dataset\n",
    "    # variáveis\n",
    "```\n",
    "\n",
    "* Exemplo:\n",
    "```yaml\n",
    "'MovieLens 1M':\n",
    "    dataset_path: ./data/datasets/MovieLens 1M/\n",
    "    train_size: 0.8\n",
    "    test_consumes: 1\n",
    "    crono: False\n",
    "    random_seed: 0\n",
    " ```\n",
    " \n",
    " * Formato padrão dos dados utilizados é composto por 4 colunas divididas por \",\":\n",
    " \n",
    "     user_id,item_id,rating,timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eccd718",
   "metadata": {},
   "source": [
    "# 2 - agents.yaml\n",
    "\n",
    "* Como o próprio nome diz, este arquivo de configuração armazena as configurações dos agentes (Recomendadores) que serão utilizados nos experimentos.\n",
    "\n",
    "\n",
    "* Template utilizado para definição de um agente:\n",
    "```yaml\n",
    "# Nome do agente recomendador\n",
    "    # Tipo do agente (irec/irec/agents.py)\n",
    "      # action_selection_policy:\n",
    "        # Politica de seleção de ações (irec/irec/action_selection_policies.py)\n",
    "          # Variáveis caso possua\n",
    "      # value_function:\n",
    "        # Função valor do agente (irec/irec/value_functions.py)\n",
    "          # Variáveis da função valor escolhida\n",
    "```\n",
    "\n",
    "* Exemplo\n",
    "```yaml\n",
    "LinearEGreedy: # Nome do agente recomendador\n",
    "  SimpleAgent: # Tipo do agente\n",
    "    action_selection_policy: \n",
    "      ASPEGreedy: # A politica de seleção de ações escolhida\n",
    "        # variaveis\n",
    "        epsilon: 0.1 \n",
    "    value_function:\n",
    "      LinearEGreedy: # Value function do agente \n",
    "        # variáveis\n",
    "        item_var: 0.01\n",
    "        iterations: 20\n",
    "        num_lat: 10\n",
    "        stop_criteria: 0.0009\n",
    "        user_var: 0.01\n",
    "        var: 0.05\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127bd779",
   "metadata": {},
   "source": [
    "# 3 - agents_search.yaml\n",
    "\n",
    "* Como cada agente pode possui diversas variáveis, é comumente utilizado uma busca dos melhores parametros a fim de se obter a melhor combinação de parametros que implicará no melhor resultado possivel. Para isso, criamos um arquivo especifico denominado **agents_search.yaml** que é responsável por armazenar todas as combinações de parametros que um determinago agente irá executar\n",
    "\n",
    "\n",
    "* O template dos agentes utilizados neste arquivo é o mesmo template utilizado em **agents.yaml**, no entando, como iremos executar vários combinações diferentes do mesmo agente, o nosso arquivo de configuração possuirá varios agentes com diferentes parametros, como mostra o exemplo a seguir.\n",
    "\n",
    "\n",
    "* No exemplo abaixo, podemos observar que o agente utilizado é o clássico **EGreedy**, com três combinações de parâmetros diferentes: epsilon: 0.2, 0.3, 0.4. Além disso, a partir do módulo irec/app/generate_search_parameters.py podemos configurar quais parâmetros queremos variar e qual o range de busca desses parametros.\n",
    "\n",
    "```yaml\n",
    "EGreedy:\n",
    "- SimpleAgent:\n",
    "    action_selection_policy:\n",
    "      ASPEGreedy:\n",
    "        epsilon: 0.4\n",
    "    value_function:\n",
    "      EGreedy: {}\n",
    "- SimpleAgent:\n",
    "    action_selection_policy:\n",
    "      ASPEGreedy:\n",
    "        epsilon: 0.3\n",
    "    value_function:\n",
    "      EGreedy: {}\n",
    "- SimpleAgent:\n",
    "    action_selection_policy:\n",
    "      ASPEGreedy:\n",
    "        epsilon: 0.2\n",
    "    value_function:\n",
    "      EGreedy: {}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973b5fb3",
   "metadata": {},
   "source": [
    "# 4 - dataset_agents.yaml\n",
    "\n",
    "* Este arquivo de configuração armazena os agentes e seus parâmetros em um determinado conjunto de dados. Como os parâmetros de um agente na maioria das vezes variam de acordo com a base de dados, é necessário armazenar quais foram os melhores parâmetros encontrados naquela base. E é neste arquivo que isso é feito. O resultado de um grid search em um agente, nos dirá quais foram os melhores parâmetros encontrados e partir dai podemos armazenar esses resultados neste arquivo de configuração, caso queira reproduzir o experimento mais tarde.\n",
    "\n",
    "* Template utilizado em dataset_agents:\n",
    "```yaml\n",
    "# Nome do dataset\n",
    "    # Agente 1\n",
    "    # Agente 2\n",
    "    ...\n",
    "    # Agente n\n",
    "```\n",
    "\n",
    "* No exemplo abaixo, podemos ver os melhores parâmetros encontrados dos agentes **LinUCB** e **LinearEGreedy** para o conjunto de dados **MovieLens 1M**\n",
    "\n",
    "```yaml\n",
    "'MovieLens 1M':\n",
    "  LinUCB:\n",
    "    SimpleAgent:\n",
    "      action_selection_policy:\n",
    "        ASPGreedy: {}\n",
    "      value_function:\n",
    "        LinUCB:\n",
    "          alpha: 1.0\n",
    "          num_lat: 10\n",
    "  LinearEGreedy:\n",
    "    SimpleAgent:\n",
    "      action_selection_policy:\n",
    "        ASPEGreedy:\n",
    "          epsilon: 0.1\n",
    "      value_function:\n",
    "        LinearEGreedy:\n",
    "          item_var: 0.01\n",
    "          iterations: 20\n",
    "          num_lat: 10\n",
    "          stop_criteria: 0.0009\n",
    "          user_var: 0.01\n",
    "          var: 0.05\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4926ae6",
   "metadata": {},
   "source": [
    "# 5 - evaluation_policies.yaml\n",
    "\n",
    "* Neste arquivo de configuração são definidas as politicas de avaliação. Para realizar um experimento, precisamos definir como será o processo de recomendação, as interações entre usuário e item e para isso criamos uma politica de avaliação de acordo com os objetivos do experimento.\n",
    "\n",
    "* Template utilizado em evaluation_policies:\n",
    "```yaml\n",
    "# Nome da politica de avaliação (irec/irec/evaluation_policies.py)\n",
    "    # variaveis\n",
    "```\n",
    "\n",
    "* No exemplo abaixo podemos ver um dos tipos de politicas implementadas no framework: **Interaction**, com seus respectivos parâmetros:\n",
    "\n",
    "```yaml\n",
    "Interaction: # A política de avaliação\n",
    "  # variáveis\n",
    "  num_interactions: 100 # Número de interações de cada usuário\n",
    "  interaction_size: 1 # O Número de itens que serão recomendados a cada interação\n",
    "  save_info: False # Salvar ou não informações obtidas durante a avaliação\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46ec8c9",
   "metadata": {},
   "source": [
    "# 6 - metric_evaluators.yaml\n",
    "\n",
    "* Neste arquivo são definidas as métricas de avaliação de um experimento. Este arquivo é responsável por fornecer detalher de como avaliar as interações realizadas durante o processo de realizado na avaliação.\n",
    "\n",
    "* Template utilizado em metric_evaluators:\n",
    "```yaml\n",
    "# Nome da métrica de avaliação (irec/irec/metric_evaluators.py)\n",
    "    # variaveis\n",
    "```\n",
    "\n",
    "* No exemplo abaixo podemos ver um tipo de métrica de avaliação: **UserCumulativeInteractionMetricEvaluator** com seus respectivos parâmetros:\n",
    "\n",
    "```yaml\n",
    "UserCumulativeInteractionMetricEvaluator:\n",
    "  # variáveis\n",
    "  interaction_size: 1 # Número de itens recomendados a cada interação\n",
    "  interactions_to_evaluate: # Interações que serão avaliadas\n",
    "    - 5\n",
    "    - 10\n",
    "    - 20\n",
    "    - 50\n",
    "    - 100\n",
    "  num_interactions: 100 # Número de interações\n",
    "  relevance_evaluator_threshold: 3.999 # Rating\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0af15e7",
   "metadata": {},
   "source": [
    "# 7 - defaults.yaml\n",
    "\n",
    "* Este arquivo de configuração é uma forma de definiar as configurações gerais para um experimento, aqui podemos definir os agentes, a base, a politica e a métrica de avaliação, além de algumas informações adicionais.\n",
    "\n",
    "\n",
    "* Exemplo\n",
    "```yaml\n",
    "agent: UCB\n",
    "agent_experiment: agent\n",
    "data_dir: data/\n",
    "dataset_experiment: dataset\n",
    "dataset_loader: 'MovieLens 1M'\n",
    "evaluation_experiment: evaluation\n",
    "evaluation_policy: Interaction\n",
    "metric: Hits\n",
    "metric_evaluator: UserCumulativeInteractionMetricEvaluator\n",
    "pdf_dir: pdf/\n",
    "tex_dir: tex/\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
